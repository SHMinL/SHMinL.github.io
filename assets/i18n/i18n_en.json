{
    "home":"Home",
    "about":"About",
    "skills":"skills",
    "tools":"Tools",
    "portfolio":"portfolio",
    "qualification":"Qualification",
    "funny":"Funny",
    "contact":"contact",
    "home__title":"Hi, I'm BigDataEngineer",
    "home__subtitle":"And Data Analyst",
    "home__description":"Proficient in Big data technology and data analysis, committed to generating value from data!",
    "home__contact":"Contact Me",
    "home__scroll-name":"Scroll down",
    "about__title":"About Myself",
    "about__subtitle":"<br>My introduction",
    "about__description":"Big data developers, responsible for data analysis and data development. A fresh student with complete knowledge reserves and good development experience. Skilled in using data analysis tools and Big data ecosystem. Full of enthusiasm and vitality for work.",
    "about-info-year-number":"01Year",
    "about-info-profile-number":"03Trems",
    "about-info-company-number":"01Family",
    "about__info-name1":"Years of <br /> experience",
    "about__info-name2":"Completed <br /> projects",
    "about__info-name3":"Companies <br /> worked",
    "download":"Download and View Resume",
    "skills__title":"Skills",
    "skills__subtitle":"<br>My technical level",
    "skill__subtitle":"Data Analyze",
    "skills__title2":"Backend developer",
    "tools_title":"Tools",
    "tools_title2":"<br>My commonly used tools",

    "toolbox-decribe-hadoop":"Master the construction of Hadoop environment, be familiar with the HDFS distributed file system, MapReduce distributed computing framework, and YARN resource scheduler, and be able to use Java programming MapReduce jobs",
    "toolbox-decribe-spark":"Understand the core idea of Spark, RDD, master cluster modes such as standalone and YARN, develop Spark SQL, Spark Streaming, and other tasks, understand transformation operations such as map and filter.",
    "toolbox-decribe-flink":"Understand stream processing theory, master Flink runtime architecture and job submission, develop Flink SQL and DataStream jobs, and implement operators using Scala or Java APIs.",
    "toolbox-decribe-hive":"Master the architecture components of Hive, proficiently use Hive SQL for data analysis on Hadoop, and understand Hive optimization methods.",
    "toolbox-decribe-kafka":"Understand Kafka architecture, master the use of themes, partitions, and producer/consumer APIs, and be familiar with Kafka high availability and scalability.",
    "toolbox-decribe-redis":"Master Redis data structures such as strings, lists, collections, etc., implement basic operations of Redis, and understand Redis's implementation of distributed locking, caching, and other functions.",
    "toolbox-decribe-numpy":"Master numpy's multi-dimensional array object ndarray, be proficient in array operations, understand the broadcasting mechanism, and master the vectorization of operations between arrays.",
    "toolbox-decribe-pandas":"Proficient in Pandas Series and DataFrame objects, master Data cleansing and preparation, and make good use of groupby grouping, merging, RESHAPE and other functions.",
    "toolbox-decribe-sckit":"earn about machine learning algorithms such as linear regression, Logistic regression, and decision tree, and use the scikit learn library to realize model training, evaluation, parameter adjustment, and prediction processes.",
    "toolbox-decribe-tensorflow":"Understand Tensorflow programming models, master the basic steps of building models, write model calculation diagrams, achieve forward propagation and reverse optimization, and complete model training and prediction",

    "qualification__title":"Qualification",
    "qualification__subtitle":"<br>My personal journey",
    "education":"Education",
    "work":"Work",
    "qualification1__title":"Computer Data Science and Big data Technology",
    "qualification1__subtitle":"zhejiang university of technology",
    "qualification2__title":"Big data development",
    "qualification2__subtitle":"Self Study",

    "qualification4__title":"Find Working",
    "qualification4__subtitle":"HangZhou",

    "portfolio__title":"Portfolio",
    "portfolio__subtitle":"<br>Most recent works",
    "portfolio1__title":"Coronary heart disease prediction system",
    "portfolio1__description":"For coronary heart disease data set, Spark is used for Data cleansing and analysis, CNN, RNN, LSTM and other multiple models are used for training and verification, and multiple model cross validation and model fusion methods are used to optimize and improve the final accuracy. Generate a dataset using GAN model and optimize training to achieve the required accuracy of the most accurate results",
    "portfolio2__title":"Today's Headline Data Analysis",
    "portfolio2__description":"Data cleansing feature selection model building and other operations are performed for today's headline dataset. Ultimately, different data items can be accurately classified with an accuracy rate of 83%. Multiple models are used for comparison and hyperparameter adjustment to achieve the prediction function.",
    "portfolio3__title":"Data analysis of COVID-19 epidemic",
    "portfolio3__description":"For the COVID-19 epidemic data, carry out visual analysis, clean the data and visualize the map, get relevant information, and then conduct combined analysis to finally get relevant conclusions.",
    
    "funny__title":"Fun projects",
    "funny__subtitle":"Try some fun features online",
    "function_describe":"Features under development...",

    "contact__title":"Contact me",
    "contact__subtitle":"<br>Get in touch",
    "tel":"Call me",
    "tel__number":"19957898403",
    "email":"E-mail",
    "email__address":"minglshen@163.com",
    "location":"Location",
    "location__detail":"HangZhou , CHINA"
}